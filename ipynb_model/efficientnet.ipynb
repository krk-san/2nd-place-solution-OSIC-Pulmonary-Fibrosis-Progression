{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011253,
     "end_time": "2021-01-11T06:36:57.098545",
     "exception": false,
     "start_time": "2021-01-11T06:36:57.087292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## About\n",
    "\n",
    "In this notebook, I trained EfficientNet-B3. The model trained here can be used to run the inference notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00999,
     "end_time": "2021-01-11T06:36:57.118961",
     "exception": false,
     "start_time": "2021-01-11T06:36:57.108971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-01-11T06:36:57.146552Z",
     "iopub.status.busy": "2021-01-11T06:36:57.145762Z",
     "iopub.status.idle": "2021-01-11T06:37:15.466831Z",
     "shell.execute_reply": "2021-01-11T06:37:15.466256Z"
    },
    "papermill": {
     "duration": 18.337878,
     "end_time": "2021-01-11T06:37:15.466949",
     "exception": false,
     "start_time": "2021-01-11T06:36:57.129071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/kerasapplications/keras-team-keras-applications-3b180cb\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.14.0)\r\n",
      "Building wheels for collected packages: Keras-Applications\r\n",
      "  Building wheel for Keras-Applications (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for Keras-Applications: filename=Keras_Applications-1.0.8-py3-none-any.whl size=50704 sha256=260f6469a8bc17a26efe860298399d7d31a3ce4e0b11489cac95d273f068d8a4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/96/13/eccdd9391bd8df958d78851b98ec4dc207ba05b67b011eb70a\r\n",
      "Successfully built Keras-Applications\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/efficientnet/efficientnet-1.1.0\r\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.16.2)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.2.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.4)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.8.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.14.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Building wheels for collected packages: efficientnet\r\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.0-py3-none-any.whl size=14141 sha256=d892a7deae453c3c2bc89c1d769a9022da07800e1d5b6276dfd394d1ceffd6da\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/24/f5/31/3cc20871288fe532128224a3f5af7b4d67efb9835bd5683522\r\n",
      "Successfully built efficientnet\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/kerasapplications/keras-team-keras-applications-3b180cb -f ./ --no-index\n",
    "!pip install ../input/efficientnet/efficientnet-1.1.0/ -f ./ --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:15.515096Z",
     "iopub.status.busy": "2021-01-11T06:37:15.514278Z",
     "iopub.status.idle": "2021-01-11T06:37:23.729764Z",
     "shell.execute_reply": "2021-01-11T06:37:23.728945Z"
    },
    "papermill": {
     "duration": 8.243393,
     "end_time": "2021-01-11T06:37:23.729877",
     "exception": false,
     "start_time": "2021-01-11T06:37:15.486484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, Add, Conv2D, AveragePooling2D, \n",
    "    LeakyReLU, Concatenate \n",
    ")\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.applications as tfa\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:23.772471Z",
     "iopub.status.busy": "2021-01-11T06:37:23.771945Z",
     "iopub.status.idle": "2021-01-11T06:37:23.775633Z",
     "shell.execute_reply": "2021-01-11T06:37:23.775236Z"
    },
    "papermill": {
     "duration": 0.027375,
     "end_time": "2021-01-11T06:37:23.775766",
     "exception": false,
     "start_time": "2021-01-11T06:37:23.748391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting Seeds\n",
    "def seed_everything(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:23.820351Z",
     "iopub.status.busy": "2021-01-11T06:37:23.819579Z",
     "iopub.status.idle": "2021-01-11T06:37:25.924720Z",
     "shell.execute_reply": "2021-01-11T06:37:25.923906Z"
    },
    "papermill": {
     "duration": 2.128806,
     "end_time": "2021-01-11T06:37:25.924905",
     "exception": false,
     "start_time": "2021-01-11T06:37:23.796099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting TensorFlow\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:26.013928Z",
     "iopub.status.busy": "2021-01-11T06:37:26.013097Z",
     "iopub.status.idle": "2021-01-11T06:37:26.025563Z",
     "shell.execute_reply": "2021-01-11T06:37:26.025139Z"
    },
    "papermill": {
     "duration": 0.066417,
     "end_time": "2021-01-11T06:37:26.025658",
     "exception": false,
     "start_time": "2021-01-11T06:37:25.959241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PATH': {'ROOT': '../input/', 'TRAIN_CSV_PATH': '../input/osic-pulmonary-fibrosis-progression/train.csv', 'TEST_CSV_PATH': '../input/osic-pulmonary-fibrosis-progression/test.csv', 'SAMPLESUB_CSV_PATH': '../input/osic-pulmonary-fibrosis-progression/sample_submission.csv', 'TRAIN_DATA_DIR': '../input/osic-pulmonary-fibrosis-progression/train/', 'TEST_DATA_DIR': '../input/osic-pulmonary-fibrosis-progression/test/', 'MASK_NOISE_DIR': '../input/osic-pulmonary-fibrosis-progression-lungs-mask/mask_noise/mask_noise/', 'TRAIN_MODEL_WEIGHTS_DIR': '../input/training-osic-2nd-place-code/'}, 'PARAMS': {'MODELS_EFF': [0], 'WEIGHT_EFF': 0.2, 'NFOLDS': 4, 'BATCH_SIZE': 128, 'EPOCHS': 300, 'EARLY_STOPPING': 150, 'NUM_LAST_FVC': 2, 'QS1': 0.2, 'QS2': 0.5, 'QS3': 0.8}, 'PARAMS_TRAIN_EFF': {'EPOCHS': 50, 'BATCH_SIZE': 8, 'NFOLDS': 5, 'LR': 0.003, 'MODEL_CLASS': 'b3'}, 'FEATURES': ['Sex_Female', 'Sex_Male', 'SmokingStatus_Currently smokes', 'SmokingStatus_Ex-smoker', 'SmokingStatus_Never smoked', 'age', 'percent', 'week', 'min_fvc']}\n"
     ]
    }
   ],
   "source": [
    "# Load Setting File\n",
    "json_open = open('../input/settings/settings.json')\n",
    "SETTINGS = json.load(json_open)\n",
    "\n",
    "PATH = SETTINGS['PATH']\n",
    "PARAMS = SETTINGS['PARAMS']\n",
    "PARAMS_TRAIN_EFF = SETTINGS['PARAMS_TRAIN_EFF']\n",
    "\n",
    "print(SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033008,
     "end_time": "2021-01-11T06:37:26.092453",
     "exception": false,
     "start_time": "2021-01-11T06:37:26.059445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0318,
     "end_time": "2021-01-11T06:37:26.156602",
     "exception": false,
     "start_time": "2021-01-11T06:37:26.124802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cluster Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:26.242324Z",
     "iopub.status.busy": "2021-01-11T06:37:26.241368Z",
     "iopub.status.idle": "2021-01-11T06:37:26.868384Z",
     "shell.execute_reply": "2021-01-11T06:37:26.867585Z"
    },
    "papermill": {
     "duration": 0.680507,
     "end_time": "2021-01-11T06:37:26.868545",
     "exception": false,
     "start_time": "2021-01-11T06:37:26.188038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88b1dc5936f42968d27a89aa1d0ead6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=176.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Load Train Data\n",
    "train_df = pd.read_csv(PATH[\"TRAIN_CSV_PATH\"]) \n",
    "\n",
    "# Linear Regression with the last few FVC\n",
    "training_patient = train_df[~train_df.duplicated(subset=['Patient'])]\n",
    "\n",
    "for patient in tqdm(train_df['Patient'].unique()): \n",
    "    idx = train_df['Patient'] == patient\n",
    "    z = ((train_df.loc[idx, 'FVC'].values[-PARAMS['NUM_LAST_FVC']:] - train_df.loc[idx, 'FVC'].values[-PARAMS['NUM_LAST_FVC']:].mean()) /\n",
    "         train_df.loc[idx, 'FVC'].values[-PARAMS['NUM_LAST_FVC']:].std())\n",
    "    reg = LinearRegression(normalize=True,fit_intercept=True).fit(train_df.loc[idx, 'Weeks'].values[-PARAMS['NUM_LAST_FVC']:].reshape(-1,1),z)\n",
    "    train_df.loc[idx, 'Intercept_2'] = reg.intercept_\n",
    "    train_df.loc[idx, 'Coef_2'] = reg.coef_[0]\n",
    "    \n",
    "training_patient = train_df.drop_duplicates('Patient') \n",
    "(ggplot(training_patient) + aes(x='Intercept_2',y='Coef_2',fill='Sex',size='FVC') + geom_point(alpha=0.4) )\n",
    "\n",
    "# Clustering Patients\n",
    "cust_array = np.array([training_patient['Intercept_2'].tolist(),training_patient['Coef_2'].tolist()])\n",
    "cust_array = cust_array.T\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "clusters = kmeans.fit(cust_array)\n",
    "training_patient['Group'] = clusters.labels_\n",
    "\n",
    "(ggplot(training_patient) + aes(x='Intercept_2',y='Coef_2',fill='Group') + geom_point(alpha=0.4) )\n",
    "\n",
    "train_df = pd.merge(train_df, training_patient[['Patient','Group']],on='Patient', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020287,
     "end_time": "2021-01-11T06:37:26.909404",
     "exception": false,
     "start_time": "2021-01-11T06:37:26.889117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:26.963651Z",
     "iopub.status.busy": "2021-01-11T06:37:26.962844Z",
     "iopub.status.idle": "2021-01-11T06:37:27.223530Z",
     "shell.execute_reply": "2021-01-11T06:37:27.222909Z"
    },
    "papermill": {
     "duration": 0.293807,
     "end_time": "2021-01-11T06:37:27.223636",
     "exception": false,
     "start_time": "2021-01-11T06:37:26.929829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b55945c9e0c46999fdddd917ce2841a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Tabular Data\n",
    "def get_tab(df):\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0] == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector) \n",
    "\n",
    "\n",
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "G = []\n",
    "for i, p in tqdm(enumerate(train_df['Patient'].unique())):\n",
    "    sub = train_df.loc[train_df['Patient'] == p, :] \n",
    "    fvc = sub['FVC'].values\n",
    "    weeks = sub['Weeks'].values\n",
    "    group = sub['Group'].values[0]\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0]\n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)\n",
    "    G.append(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02103,
     "end_time": "2021-01-11T06:37:27.266522",
     "exception": false,
     "start_time": "2021-01-11T06:37:27.245492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021218,
     "end_time": "2021-01-11T06:37:27.308840",
     "exception": false,
     "start_time": "2021-01-11T06:37:27.287622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:27.374547Z",
     "iopub.status.busy": "2021-01-11T06:37:27.373978Z",
     "iopub.status.idle": "2021-01-11T06:37:27.377939Z",
     "shell.execute_reply": "2021-01-11T06:37:27.378440Z"
    },
    "papermill": {
     "duration": 0.048549,
     "end_time": "2021-01-11T06:37:27.378567",
     "exception": false,
     "start_time": "2021-01-11T06:37:27.330018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Image Data\n",
    "def get_img(path):\n",
    "    d = pydicom.dcmread(path)\n",
    "    return cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512, 512))\n",
    "\n",
    "\n",
    "# Load Data\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size=PARAMS_TRAIN_EFF['BATCH_SIZE']):\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train_df['Patient'].values:\n",
    "            self.train_data[p] = os.listdir(f'{PATH[\"TRAIN_DATA_DIR\"]}{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size)\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0]\n",
    "                img = get_img(f'{PATH[\"TRAIN_DATA_DIR\"]}{k}/{i}')\n",
    "                x.append(img)\n",
    "                a.append(self.a[k])\n",
    "                tab.append(self.tab[k])\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab)\n",
    "        x = np.expand_dims(x, axis=-1)\n",
    "        return [x, tab] , a\n",
    "    \n",
    "    \n",
    "# Make Model\n",
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,))\n",
    "    x2 = tf.keras.layers.GaussianNoise(0.2)(inp2)\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021127,
     "end_time": "2021-01-11T06:37:27.421453",
     "exception": false,
     "start_time": "2021-01-11T06:37:27.400326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T06:37:27.478992Z",
     "iopub.status.busy": "2021-01-11T06:37:27.477813Z",
     "iopub.status.idle": "2021-01-11T08:00:56.809931Z",
     "shell.execute_reply": "2021-01-11T08:00:56.809437Z"
    },
    "papermill": {
     "duration": 5009.368281,
     "end_time": "2021-01-11T08:00:56.810851",
     "exception": false,
     "start_time": "2021-01-11T06:37:27.442570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "####### Fold 0 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5560\n",
      "Epoch 00001: val_loss improved from inf to 10746.61914, saving model to fold-0.h5\n",
      "32/32 [==============================] - 22s 701ms/step - loss: 4.5560 - val_loss: 10746.6191\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0584\n",
      "Epoch 00002: val_loss improved from 10746.61914 to 4.47555, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 634ms/step - loss: 5.0584 - val_loss: 4.4755\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9857\n",
      "Epoch 00003: val_loss did not improve from 4.47555\n",
      "32/32 [==============================] - 19s 601ms/step - loss: 4.9857 - val_loss: 329.1877\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5657\n",
      "Epoch 00004: val_loss improved from 4.47555 to 4.07307, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 631ms/step - loss: 4.5657 - val_loss: 4.0731\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6905\n",
      "Epoch 00005: val_loss did not improve from 4.07307\n",
      "32/32 [==============================] - 19s 584ms/step - loss: 4.6905 - val_loss: 4.4172\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6554\n",
      "Epoch 00006: val_loss improved from 4.07307 to 3.93673, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 630ms/step - loss: 4.6554 - val_loss: 3.9367\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2625\n",
      "Epoch 00007: val_loss did not improve from 3.93673\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 4.2625 - val_loss: 44.7519\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4893\n",
      "Epoch 00008: val_loss did not improve from 3.93673\n",
      "32/32 [==============================] - 19s 581ms/step - loss: 4.4893 - val_loss: 5.1883\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1209\n",
      "Epoch 00009: val_loss did not improve from 3.93673\n",
      "32/32 [==============================] - 19s 583ms/step - loss: 4.1209 - val_loss: 72.7092\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9289\n",
      "Epoch 00010: val_loss improved from 3.93673 to 3.90206, saving model to fold-0.h5\n",
      "32/32 [==============================] - 19s 602ms/step - loss: 3.9289 - val_loss: 3.9021\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5409\n",
      "Epoch 00011: val_loss did not improve from 3.90206\n",
      "32/32 [==============================] - 18s 578ms/step - loss: 4.5409 - val_loss: 13.0951\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6095\n",
      "Epoch 00012: val_loss did not improve from 3.90206\n",
      "32/32 [==============================] - 19s 581ms/step - loss: 4.6095 - val_loss: 14.8278\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2684\n",
      "Epoch 00013: val_loss did not improve from 3.90206\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 4.2684 - val_loss: 24.0320\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0692\n",
      "Epoch 00014: val_loss improved from 3.90206 to 3.86635, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 612ms/step - loss: 4.0692 - val_loss: 3.8664\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8120\n",
      "Epoch 00015: val_loss did not improve from 3.86635\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 3.8120 - val_loss: 6.3446\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7744\n",
      "Epoch 00016: val_loss did not improve from 3.86635\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 4.7744 - val_loss: 7.7776\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6949\n",
      "Epoch 00017: val_loss did not improve from 3.86635\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.6949 - val_loss: 4.4721\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5020\n",
      "Epoch 00018: val_loss did not improve from 3.86635\n",
      "32/32 [==============================] - 18s 575ms/step - loss: 4.5020 - val_loss: 5.4408\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3640\n",
      "Epoch 00019: val_loss did not improve from 3.86635\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.3640 - val_loss: 4.9148\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0055\n",
      "Epoch 00020: val_loss did not improve from 3.86635\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 5.0055 - val_loss: 85.2618\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1075\n",
      "Epoch 00021: val_loss did not improve from 3.86635\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.1075 - val_loss: 4.1880\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1882\n",
      "Epoch 00022: val_loss improved from 3.86635 to 3.69809, saving model to fold-0.h5\n",
      "32/32 [==============================] - 19s 593ms/step - loss: 4.1882 - val_loss: 3.6981\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3960\n",
      "Epoch 00023: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.3960 - val_loss: 3.8124\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2587\n",
      "Epoch 00024: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.2587 - val_loss: 4.3554\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4580\n",
      "Epoch 00025: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 570ms/step - loss: 4.4580 - val_loss: 4.5143\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9669\n",
      "Epoch 00026: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 3.9669 - val_loss: 4.1253\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1128\n",
      "Epoch 00027: val_loss did not improve from 3.69809\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.1128 - val_loss: 4.3319\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8128\n",
      "Epoch 00028: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.8128 - val_loss: 3.7743\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3473\n",
      "Epoch 00029: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.3473 - val_loss: 3.9048\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4330\n",
      "Epoch 00030: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.4330 - val_loss: 4.2985\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2787\n",
      "Epoch 00031: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.2787 - val_loss: 4.0704\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5747\n",
      "Epoch 00032: val_loss did not improve from 3.69809\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 3.5747 - val_loss: 4.3029\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2491\n",
      "Epoch 00033: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.2491 - val_loss: 3.7582\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6045\n",
      "Epoch 00034: val_loss did not improve from 3.69809\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6045 - val_loss: 4.0439\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3148\n",
      "Epoch 00035: val_loss improved from 3.69809 to 3.64847, saving model to fold-0.h5\n",
      "32/32 [==============================] - 19s 598ms/step - loss: 4.3148 - val_loss: 3.6485\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1869\n",
      "Epoch 00036: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 567ms/step - loss: 4.1869 - val_loss: 3.6860\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2665\n",
      "Epoch 00037: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.2665 - val_loss: 4.1281\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1948\n",
      "Epoch 00038: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.1948 - val_loss: 4.1460\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5106\n",
      "Epoch 00039: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.5106 - val_loss: 4.5742\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1564\n",
      "Epoch 00040: val_loss did not improve from 3.64847\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.1564 - val_loss: 4.1646\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1947\n",
      "Epoch 00041: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.1947 - val_loss: 4.1185\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3528\n",
      "Epoch 00042: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.3528 - val_loss: 4.0120\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5283\n",
      "Epoch 00043: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.5283 - val_loss: 3.8226\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1877\n",
      "Epoch 00044: val_loss did not improve from 3.64847\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.1877 - val_loss: 4.3646\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9418\n",
      "Epoch 00045: val_loss did not improve from 3.64847\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 3.9418 - val_loss: 4.2261\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0577\n",
      "Epoch 00046: val_loss improved from 3.64847 to 3.62009, saving model to fold-0.h5\n",
      "32/32 [==============================] - 19s 593ms/step - loss: 4.0577 - val_loss: 3.6201\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4406\n",
      "Epoch 00047: val_loss did not improve from 3.62009\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.4406 - val_loss: 3.9641\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4738\n",
      "Epoch 00048: val_loss did not improve from 3.62009\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.4738 - val_loss: 4.0463\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0356\n",
      "Epoch 00049: val_loss did not improve from 3.62009\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.0356 - val_loss: 4.1404\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5933\n",
      "Epoch 00050: val_loss did not improve from 3.62009\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.5933 - val_loss: 4.0328\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 1 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3717\n",
      "Epoch 00001: val_loss improved from inf to 7336.09570, saving model to fold-1.h5\n",
      "32/32 [==============================] - 22s 681ms/step - loss: 4.3717 - val_loss: 7336.0957\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4547\n",
      "Epoch 00002: val_loss did not improve from 7336.09570\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.4547 - val_loss: 369444.4375\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7686\n",
      "Epoch 00003: val_loss did not improve from 7336.09570\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 3.7686 - val_loss: 29882.2402\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1974\n",
      "Epoch 00004: val_loss improved from 7336.09570 to 195.83429, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 612ms/step - loss: 4.1974 - val_loss: 195.8343\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0221\n",
      "Epoch 00005: val_loss improved from 195.83429 to 11.21794, saving model to fold-1.h5\n",
      "32/32 [==============================] - 19s 605ms/step - loss: 4.0221 - val_loss: 11.2179\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7037\n",
      "Epoch 00006: val_loss did not improve from 11.21794\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 3.7037 - val_loss: 2508.6895\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8977\n",
      "Epoch 00007: val_loss improved from 11.21794 to 6.64202, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 613ms/step - loss: 3.8977 - val_loss: 6.6420\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5676\n",
      "Epoch 00008: val_loss improved from 6.64202 to 5.90221, saving model to fold-1.h5\n",
      "32/32 [==============================] - 19s 595ms/step - loss: 4.5676 - val_loss: 5.9022\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3873\n",
      "Epoch 00009: val_loss did not improve from 5.90221\n",
      "32/32 [==============================] - 18s 571ms/step - loss: 3.3873 - val_loss: 6.1317\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2656\n",
      "Epoch 00010: val_loss did not improve from 5.90221\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 4.2656 - val_loss: 443.4168\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4949\n",
      "Epoch 00011: val_loss did not improve from 5.90221\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 3.4949 - val_loss: 6.2821\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2042\n",
      "Epoch 00012: val_loss did not improve from 5.90221\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 4.2042 - val_loss: 7.5250\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1145\n",
      "Epoch 00013: val_loss did not improve from 5.90221\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 567ms/step - loss: 4.1145 - val_loss: 6.4342\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0858\n",
      "Epoch 00014: val_loss improved from 5.90221 to 5.71205, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 610ms/step - loss: 4.0858 - val_loss: 5.7121\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7531\n",
      "Epoch 00015: val_loss did not improve from 5.71205\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 3.7531 - val_loss: 6.5774\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9684\n",
      "Epoch 00016: val_loss did not improve from 5.71205\n",
      "32/32 [==============================] - 18s 570ms/step - loss: 3.9684 - val_loss: 5.8018\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8139\n",
      "Epoch 00017: val_loss did not improve from 5.71205\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 3.8139 - val_loss: 6.5741\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6640\n",
      "Epoch 00018: val_loss did not improve from 5.71205\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 3.6640 - val_loss: 7.1337\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0757\n",
      "Epoch 00019: val_loss did not improve from 5.71205\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.0757 - val_loss: 6.6559\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7740\n",
      "Epoch 00020: val_loss improved from 5.71205 to 5.31896, saving model to fold-1.h5\n",
      "32/32 [==============================] - 19s 601ms/step - loss: 3.7740 - val_loss: 5.3190\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7277\n",
      "Epoch 00021: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 3.7277 - val_loss: 6.4358\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6656\n",
      "Epoch 00022: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 3.6656 - val_loss: 5.8449\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5181\n",
      "Epoch 00023: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 3.5181 - val_loss: 5.6211\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4923\n",
      "Epoch 00024: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 3.4923 - val_loss: 6.1141\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8006\n",
      "Epoch 00025: val_loss did not improve from 5.31896\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 3.8006 - val_loss: 6.9184\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6937\n",
      "Epoch 00026: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 19s 580ms/step - loss: 3.6937 - val_loss: 5.5046\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5689\n",
      "Epoch 00027: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 3.5689 - val_loss: 5.4100\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2134\n",
      "Epoch 00028: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.2134 - val_loss: 7.3421\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5016\n",
      "Epoch 00029: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 3.5016 - val_loss: 5.9420\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8216\n",
      "Epoch 00030: val_loss did not improve from 5.31896\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 3.8216 - val_loss: 6.3749\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1680\n",
      "Epoch 00031: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.1680 - val_loss: 6.6277\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8546\n",
      "Epoch 00032: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 3.8546 - val_loss: 5.4715\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5499\n",
      "Epoch 00033: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 3.5499 - val_loss: 6.3799\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7000\n",
      "Epoch 00034: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 3.7000 - val_loss: 6.3731\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0210\n",
      "Epoch 00035: val_loss did not improve from 5.31896\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.0210 - val_loss: 5.7031\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6826\n",
      "Epoch 00036: val_loss did not improve from 5.31896\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 3.6826 - val_loss: 6.8249\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8928\n",
      "Epoch 00037: val_loss improved from 5.31896 to 5.30133, saving model to fold-1.h5\n",
      "32/32 [==============================] - 19s 596ms/step - loss: 3.8928 - val_loss: 5.3013\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6639\n",
      "Epoch 00038: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 3.6639 - val_loss: 5.9430\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8367\n",
      "Epoch 00039: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 3.8367 - val_loss: 6.0022\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1298\n",
      "Epoch 00040: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.1298 - val_loss: 6.5371\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7708\n",
      "Epoch 00041: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 3.7708 - val_loss: 6.1967\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0147\n",
      "Epoch 00042: val_loss did not improve from 5.30133\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.0147 - val_loss: 6.5772\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9375\n",
      "Epoch 00043: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 3.9375 - val_loss: 5.7240\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8376\n",
      "Epoch 00044: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 3.8376 - val_loss: 6.4018\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8157\n",
      "Epoch 00045: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 3.8157 - val_loss: 6.1896\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9266\n",
      "Epoch 00046: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 3.9266 - val_loss: 5.8165\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1082\n",
      "Epoch 00047: val_loss did not improve from 5.30133\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.1082 - val_loss: 5.7321\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9711\n",
      "Epoch 00048: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 3.9711 - val_loss: 6.5834\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6499\n",
      "Epoch 00049: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 3.6499 - val_loss: 5.3785\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7743\n",
      "Epoch 00050: val_loss did not improve from 5.30133\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 3.7743 - val_loss: 5.9886\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 2 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5562\n",
      "Epoch 00001: val_loss improved from inf to 7023.61377, saving model to fold-2.h5\n",
      "32/32 [==============================] - 21s 670ms/step - loss: 5.5562 - val_loss: 7023.6138\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7755\n",
      "Epoch 00002: val_loss improved from 7023.61377 to 590.48499, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 616ms/step - loss: 4.7755 - val_loss: 590.4850\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8116\n",
      "Epoch 00003: val_loss did not improve from 590.48499\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.8116 - val_loss: 1997.5773\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1304\n",
      "Epoch 00004: val_loss improved from 590.48499 to 16.81539, saving model to fold-2.h5\n",
      "32/32 [==============================] - 19s 602ms/step - loss: 5.1304 - val_loss: 16.8154\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2351\n",
      "Epoch 00005: val_loss did not improve from 16.81539\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.2351 - val_loss: 1554.8701\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7362\n",
      "Epoch 00006: val_loss did not improve from 16.81539\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 4.7362 - val_loss: 17.4279\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8069\n",
      "Epoch 00007: val_loss did not improve from 16.81539\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.8069 - val_loss: 48.8320\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9421\n",
      "Epoch 00008: val_loss did not improve from 16.81539\n",
      "32/32 [==============================] - 19s 582ms/step - loss: 3.9421 - val_loss: 1641.2861\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3673\n",
      "Epoch 00009: val_loss did not improve from 16.81539\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.3673 - val_loss: 83.6502\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0037\n",
      "Epoch 00010: val_loss did not improve from 16.81539\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 5.0037 - val_loss: 26.1389\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6960\n",
      "Epoch 00011: val_loss improved from 16.81539 to 6.66639, saving model to fold-2.h5\n",
      "32/32 [==============================] - 19s 602ms/step - loss: 4.6960 - val_loss: 6.6664\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0327\n",
      "Epoch 00012: val_loss did not improve from 6.66639\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 5.0327 - val_loss: 49.2146\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8820\n",
      "Epoch 00013: val_loss improved from 6.66639 to 3.53388, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 3.8820 - val_loss: 3.5339\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7686\n",
      "Epoch 00014: val_loss improved from 3.53388 to 3.16411, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 612ms/step - loss: 3.7686 - val_loss: 3.1641\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6804\n",
      "Epoch 00015: val_loss did not improve from 3.16411\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6804 - val_loss: 3.6625\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7100\n",
      "Epoch 00016: val_loss did not improve from 3.16411\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.7100 - val_loss: 5.5657\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1546\n",
      "Epoch 00017: val_loss did not improve from 3.16411\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 5.1546 - val_loss: 3.7935\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2191\n",
      "Epoch 00018: val_loss did not improve from 3.16411\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.2191 - val_loss: 3.2375\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3742\n",
      "Epoch 00019: val_loss did not improve from 3.16411\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.3742 - val_loss: 3.5641\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5180\n",
      "Epoch 00020: val_loss did not improve from 3.16411\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.5180 - val_loss: 3.3143\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2370\n",
      "Epoch 00021: val_loss improved from 3.16411 to 2.90331, saving model to fold-2.h5\n",
      "32/32 [==============================] - 19s 606ms/step - loss: 4.2370 - val_loss: 2.9033\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2686\n",
      "Epoch 00022: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.2686 - val_loss: 3.3875\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6898\n",
      "Epoch 00023: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6898 - val_loss: 3.2307\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6967\n",
      "Epoch 00024: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 4.6967 - val_loss: 3.7626\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9123\n",
      "Epoch 00025: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.9123 - val_loss: 4.0943\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3228\n",
      "Epoch 00026: val_loss did not improve from 2.90331\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.3228 - val_loss: 4.0600\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9558\n",
      "Epoch 00027: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 571ms/step - loss: 4.9558 - val_loss: 3.3601\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3727\n",
      "Epoch 00028: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.3727 - val_loss: 3.4412\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6831\n",
      "Epoch 00029: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6831 - val_loss: 3.7508\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8788\n",
      "Epoch 00030: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.8788 - val_loss: 3.0624\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2171\n",
      "Epoch 00031: val_loss did not improve from 2.90331\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.2171 - val_loss: 3.5689\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00032: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6809 - val_loss: 3.9053\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1708\n",
      "Epoch 00033: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.1708 - val_loss: 3.8694\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3801\n",
      "Epoch 00034: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.3801 - val_loss: 3.9201\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6623\n",
      "Epoch 00035: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6623 - val_loss: 3.4692\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2765\n",
      "Epoch 00036: val_loss did not improve from 2.90331\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.2765 - val_loss: 3.7215\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7452\n",
      "Epoch 00037: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.7452 - val_loss: 3.2965\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9063\n",
      "Epoch 00038: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 3.9063 - val_loss: 3.4997\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6367\n",
      "Epoch 00039: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6367 - val_loss: 3.2475\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0045\n",
      "Epoch 00040: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.0045 - val_loss: 3.2399\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8453\n",
      "Epoch 00041: val_loss did not improve from 2.90331\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.8453 - val_loss: 3.6385\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2259\n",
      "Epoch 00042: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.2259 - val_loss: 3.8969\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4571\n",
      "Epoch 00043: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.4571 - val_loss: 3.6392\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9187\n",
      "Epoch 00044: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.9187 - val_loss: 3.3759\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1897\n",
      "Epoch 00045: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.1897 - val_loss: 3.0855\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3061\n",
      "Epoch 00046: val_loss did not improve from 2.90331\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.3061 - val_loss: 3.8284\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4314\n",
      "Epoch 00047: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.4314 - val_loss: 3.1840\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5643\n",
      "Epoch 00048: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.5643 - val_loss: 3.4171\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4820\n",
      "Epoch 00049: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.4820 - val_loss: 3.3041\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5354\n",
      "Epoch 00050: val_loss did not improve from 2.90331\n",
      "32/32 [==============================] - 18s 570ms/step - loss: 4.5354 - val_loss: 2.9107\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 3 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2074\n",
      "Epoch 00001: val_loss improved from inf to 4745.56348, saving model to fold-3.h5\n",
      "32/32 [==============================] - 22s 682ms/step - loss: 5.2074 - val_loss: 4745.5635\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1927\n",
      "Epoch 00002: val_loss improved from 4745.56348 to 68.68135, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 600ms/step - loss: 4.1927 - val_loss: 68.6814\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5294\n",
      "Epoch 00003: val_loss did not improve from 68.68135\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.5294 - val_loss: 89568.3203\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2972\n",
      "Epoch 00004: val_loss did not improve from 68.68135\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.2972 - val_loss: 19513.9141\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9959\n",
      "Epoch 00005: val_loss did not improve from 68.68135\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.9959 - val_loss: 14019.4492\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6969\n",
      "Epoch 00006: val_loss did not improve from 68.68135\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6969 - val_loss: 21422.0957\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9218\n",
      "Epoch 00007: val_loss did not improve from 68.68135\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.9218 - val_loss: 11959.2988\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5907\n",
      "Epoch 00008: val_loss improved from 68.68135 to 26.82872, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 596ms/step - loss: 4.5907 - val_loss: 26.8287\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1456\n",
      "Epoch 00009: val_loss improved from 26.82872 to 4.15246, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 591ms/step - loss: 4.1456 - val_loss: 4.1525\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2477\n",
      "Epoch 00010: val_loss did not improve from 4.15246\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.2477 - val_loss: 4.4282\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4970\n",
      "Epoch 00011: val_loss did not improve from 4.15246\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.4970 - val_loss: 4.8819\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1862\n",
      "Epoch 00012: val_loss improved from 4.15246 to 3.65785, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 594ms/step - loss: 4.1862 - val_loss: 3.6579\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6476\n",
      "Epoch 00013: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.6476 - val_loss: 3.7820\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5344\n",
      "Epoch 00014: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.5344 - val_loss: 4.0274\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8462\n",
      "Epoch 00015: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 3.8462 - val_loss: 4.8215\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1747\n",
      "Epoch 00016: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.1747 - val_loss: 3.9980\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4537\n",
      "Epoch 00017: val_loss did not improve from 3.65785\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.4537 - val_loss: 3.9124\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7135\n",
      "Epoch 00018: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 3.7135 - val_loss: 3.8788\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2375\n",
      "Epoch 00019: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.2375 - val_loss: 4.0757\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5161\n",
      "Epoch 00020: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.5161 - val_loss: 3.6679\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2901\n",
      "Epoch 00021: val_loss did not improve from 3.65785\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.2901 - val_loss: 4.0334\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7304\n",
      "Epoch 00022: val_loss improved from 3.65785 to 3.63044, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 608ms/step - loss: 4.7304 - val_loss: 3.6304\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4524\n",
      "Epoch 00023: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.4524 - val_loss: 3.9551\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2168\n",
      "Epoch 00024: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.2168 - val_loss: 3.6413\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1977\n",
      "Epoch 00025: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.1977 - val_loss: 3.8533\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3171\n",
      "Epoch 00026: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.3171 - val_loss: 3.8851\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1434\n",
      "Epoch 00027: val_loss did not improve from 3.63044\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.1434 - val_loss: 4.2374\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6661\n",
      "Epoch 00028: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6661 - val_loss: 4.0914\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1591\n",
      "Epoch 00029: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.1591 - val_loss: 3.8354\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2486\n",
      "Epoch 00030: val_loss did not improve from 3.63044\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.2486 - val_loss: 3.8979\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4548\n",
      "Epoch 00031: val_loss improved from 3.63044 to 3.59991, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 593ms/step - loss: 4.4548 - val_loss: 3.5999\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4508\n",
      "Epoch 00032: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.4508 - val_loss: 3.7007\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4476\n",
      "Epoch 00033: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.4476 - val_loss: 4.2389\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8039\n",
      "Epoch 00034: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.8039 - val_loss: 3.7112\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6140\n",
      "Epoch 00035: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.6140 - val_loss: 4.4966\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1986\n",
      "Epoch 00036: val_loss did not improve from 3.59991\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.1986 - val_loss: 4.2213\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9442\n",
      "Epoch 00037: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 3.9442 - val_loss: 4.1577\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9933\n",
      "Epoch 00038: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 3.9933 - val_loss: 3.8403\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0116\n",
      "Epoch 00039: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.0116 - val_loss: 3.9827\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9112\n",
      "Epoch 00040: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 3.9112 - val_loss: 3.6416\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8400\n",
      "Epoch 00041: val_loss did not improve from 3.59991\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 3.8400 - val_loss: 4.1798\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5492\n",
      "Epoch 00042: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.5492 - val_loss: 4.0830\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8416\n",
      "Epoch 00043: val_loss did not improve from 3.59991\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.8416 - val_loss: 3.9170\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3651\n",
      "Epoch 00044: val_loss improved from 3.59991 to 3.28363, saving model to fold-3.h5\n",
      "32/32 [==============================] - 19s 595ms/step - loss: 4.3651 - val_loss: 3.2836\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7641\n",
      "Epoch 00045: val_loss did not improve from 3.28363\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.7641 - val_loss: 3.6430\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9245\n",
      "Epoch 00046: val_loss did not improve from 3.28363\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 3.9245 - val_loss: 3.7403\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7919\n",
      "Epoch 00047: val_loss did not improve from 3.28363\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.7919 - val_loss: 4.0348\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8160\n",
      "Epoch 00048: val_loss did not improve from 3.28363\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.8160 - val_loss: 4.2846\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0366\n",
      "Epoch 00049: val_loss did not improve from 3.28363\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.0366 - val_loss: 4.0175\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5433\n",
      "Epoch 00050: val_loss did not improve from 3.28363\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.5433 - val_loss: 3.7115\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 4 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.3839\n",
      "Epoch 00001: val_loss improved from inf to 2719.03784, saving model to fold-4.h5\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 5.3839 - val_loss: 2719.0378\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8230\n",
      "Epoch 00002: val_loss improved from 2719.03784 to 874.84930, saving model to fold-4.h5\n",
      "32/32 [==============================] - 19s 606ms/step - loss: 4.8230 - val_loss: 874.8493\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6328\n",
      "Epoch 00003: val_loss improved from 874.84930 to 681.22015, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 4.6328 - val_loss: 681.2202\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5420\n",
      "Epoch 00004: val_loss improved from 681.22015 to 116.50384, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 629ms/step - loss: 4.5420 - val_loss: 116.5038\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1492\n",
      "Epoch 00005: val_loss improved from 116.50384 to 4.43662, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 613ms/step - loss: 4.1492 - val_loss: 4.4366\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3069\n",
      "Epoch 00006: val_loss did not improve from 4.43662\n",
      "32/32 [==============================] - 18s 575ms/step - loss: 4.3069 - val_loss: 4.9148\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4836\n",
      "Epoch 00007: val_loss did not improve from 4.43662\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 4.4836 - val_loss: 1550.9698\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5232\n",
      "Epoch 00008: val_loss did not improve from 4.43662\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.5232 - val_loss: 49.5136\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1407\n",
      "Epoch 00009: val_loss improved from 4.43662 to 4.12894, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 623ms/step - loss: 4.1407 - val_loss: 4.1289\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4957\n",
      "Epoch 00010: val_loss did not improve from 4.12894\n",
      "32/32 [==============================] - 18s 567ms/step - loss: 4.4957 - val_loss: 113.2773\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5785\n",
      "Epoch 00011: val_loss did not improve from 4.12894\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.5785 - val_loss: 5.4850\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7438\n",
      "Epoch 00012: val_loss did not improve from 4.12894\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 3.7438 - val_loss: 130.8487\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7029\n",
      "Epoch 00013: val_loss did not improve from 4.12894\n",
      "32/32 [==============================] - 18s 571ms/step - loss: 4.7029 - val_loss: 6.3811\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1075\n",
      "Epoch 00014: val_loss did not improve from 4.12894\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 5.1075 - val_loss: 24.1988\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5970\n",
      "Epoch 00015: val_loss did not improve from 4.12894\n",
      "32/32 [==============================] - 18s 571ms/step - loss: 4.5970 - val_loss: 7.0640\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7242\n",
      "Epoch 00016: val_loss improved from 4.12894 to 3.85866, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 613ms/step - loss: 3.7242 - val_loss: 3.8587\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8844\n",
      "Epoch 00017: val_loss did not improve from 3.85866\n",
      "32/32 [==============================] - 18s 571ms/step - loss: 4.8844 - val_loss: 3.9624\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0752\n",
      "Epoch 00018: val_loss did not improve from 3.85866\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.0752 - val_loss: 4.9653\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7064\n",
      "Epoch 00019: val_loss did not improve from 3.85866\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.7064 - val_loss: 4.2869\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3008\n",
      "Epoch 00020: val_loss did not improve from 3.85866\n",
      "32/32 [==============================] - 18s 576ms/step - loss: 4.3008 - val_loss: 4.0497\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4435\n",
      "Epoch 00021: val_loss did not improve from 3.85866\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.4435 - val_loss: 4.2714\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6627\n",
      "Epoch 00022: val_loss did not improve from 3.85866\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.6627 - val_loss: 4.3608\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9880\n",
      "Epoch 00023: val_loss did not improve from 3.85866\n",
      "32/32 [==============================] - 18s 574ms/step - loss: 3.9880 - val_loss: 4.4211\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6058\n",
      "Epoch 00024: val_loss improved from 3.85866 to 3.84395, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 610ms/step - loss: 4.6058 - val_loss: 3.8440\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0114\n",
      "Epoch 00025: val_loss did not improve from 3.84395\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.0114 - val_loss: 4.2692\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3473\n",
      "Epoch 00026: val_loss did not improve from 3.84395\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.3473 - val_loss: 4.1451\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0519\n",
      "Epoch 00027: val_loss did not improve from 3.84395\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.0519 - val_loss: 3.9986\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1690\n",
      "Epoch 00028: val_loss improved from 3.84395 to 3.61299, saving model to fold-4.h5\n",
      "32/32 [==============================] - 19s 603ms/step - loss: 4.1690 - val_loss: 3.6130\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3407\n",
      "Epoch 00029: val_loss did not improve from 3.61299\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.3407 - val_loss: 4.5320\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3401\n",
      "Epoch 00030: val_loss improved from 3.61299 to 3.41269, saving model to fold-4.h5\n",
      "32/32 [==============================] - 19s 599ms/step - loss: 4.3401 - val_loss: 3.4127\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4149\n",
      "Epoch 00031: val_loss did not improve from 3.41269\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.4149 - val_loss: 4.2575\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3354\n",
      "Epoch 00032: val_loss did not improve from 3.41269\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.3354 - val_loss: 4.5444\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0637\n",
      "Epoch 00033: val_loss did not improve from 3.41269\n",
      "32/32 [==============================] - 18s 573ms/step - loss: 4.0637 - val_loss: 4.0804\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4970\n",
      "Epoch 00034: val_loss did not improve from 3.41269\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.4970 - val_loss: 3.9754\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8437\n",
      "Epoch 00035: val_loss did not improve from 3.41269\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.8437 - val_loss: 3.8776\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4231\n",
      "Epoch 00036: val_loss improved from 3.41269 to 3.41020, saving model to fold-4.h5\n",
      "32/32 [==============================] - 19s 597ms/step - loss: 4.4231 - val_loss: 3.4102\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1759\n",
      "Epoch 00037: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.1759 - val_loss: 4.0203\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0052\n",
      "Epoch 00038: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.0052 - val_loss: 4.2670\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9619\n",
      "Epoch 00039: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 3.9619 - val_loss: 4.5756\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4100\n",
      "Epoch 00040: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.4100 - val_loss: 4.5977\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2904\n",
      "Epoch 00041: val_loss did not improve from 3.41020\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 567ms/step - loss: 4.2904 - val_loss: 4.3792\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6132\n",
      "Epoch 00042: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 571ms/step - loss: 3.6132 - val_loss: 4.5435\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0939\n",
      "Epoch 00043: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.0939 - val_loss: 3.9875\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5529\n",
      "Epoch 00044: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 575ms/step - loss: 4.5529 - val_loss: 4.2025\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2710\n",
      "Epoch 00045: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 4.2710 - val_loss: 4.2673\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4564\n",
      "Epoch 00046: val_loss did not improve from 3.41020\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.4564 - val_loss: 3.7422\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5544\n",
      "Epoch 00047: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.5544 - val_loss: 4.2000\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8620\n",
      "Epoch 00048: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 3.8620 - val_loss: 4.0308\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3558\n",
      "Epoch 00049: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.3558 - val_loss: 4.3890\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3913\n",
      "Epoch 00050: val_loss did not improve from 3.41020\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.3913 - val_loss: 4.1562\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "# Split patients data with StratifiedKFold based on the above grouping.\n",
    "P = np.array(P)\n",
    "G = np.array(G)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = PARAMS_TRAIN_EFF['NFOLDS'])\n",
    "splitter = skf.split(P,G)\n",
    "\n",
    "# Cross-Validation\n",
    "subs = []\n",
    "folds_history = []\n",
    "for fold, (tr_idx, val_idx) in enumerate(splitter):\n",
    "    print('#####################')\n",
    "    print('####### Fold %i ######'%fold)\n",
    "    print('#####################')\n",
    "    print('Training...')\n",
    "    \n",
    "    er = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-3,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    cpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='fold-%i.h5'%fold,\n",
    "        monitor='val_loss', \n",
    "        verbose=1, \n",
    "        save_best_only=True,\n",
    "        mode='auto'\n",
    "    )\n",
    "\n",
    "    rlp = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5,\n",
    "        patience=5, \n",
    "        verbose=1, \n",
    "        min_lr=1e-8\n",
    "    )\n",
    "    model = build_model(model_class=PARAMS_TRAIN_EFF['MODEL_CLASS'])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=PARAMS_TRAIN_EFF['LR']), loss=\"mae\") \n",
    "    history = model.fit_generator(IGenerator(keys=P[tr_idx], \n",
    "                                   a = A, \n",
    "                                   tab = TAB), \n",
    "                        steps_per_epoch = 32,\n",
    "                        validation_data=IGenerator(keys=P[val_idx], \n",
    "                                   a = A, \n",
    "                                   tab = TAB),\n",
    "                        validation_steps = 16, \n",
    "                        callbacks = [cpt, rlp], \n",
    "                        epochs=PARAMS_TRAIN_EFF['EPOCHS'])\n",
    "    folds_history.append(history.history)\n",
    "    print('Training done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.716124,
     "end_time": "2021-01-11T08:01:02.326965",
     "exception": false,
     "start_time": "2021-01-11T08:00:59.610841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-01-11T08:01:07.073117Z",
     "iopub.status.busy": "2021-01-11T08:01:07.072325Z",
     "iopub.status.idle": "2021-01-11T08:01:07.076037Z",
     "shell.execute_reply": "2021-01-11T08:01:07.076463Z"
    },
    "papermill": {
     "duration": 2.380019,
     "end_time": "2021-01-11T08:01:07.076606",
     "exception": false,
     "start_time": "2021-01-11T08:01:04.696587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean CV MAE is: 3.703711175918579\n"
     ]
    }
   ],
   "source": [
    "mean_val_loss = np.mean([np.min(h['val_loss']) for h in folds_history])\n",
    "print('Our mean CV MAE is: ' + str(mean_val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 5057.796796,
   "end_time": "2021-01-11T08:01:11.044505",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-11T06:36:53.247709",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "006ecc8257f24549b93ec99b8aec035b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "00dcc591599749a6a5249f06f90df1c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "245d1992fe6943f484ee61f0d29ba38c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a83c7beff0949b6aed3835834dfbe12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bc237e02a6f41d0bb047f52911a4086": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2a83c7beff0949b6aed3835834dfbe12",
       "placeholder": "​",
       "style": "IPY_MODEL_2bdfcfa9324a44e496d0f13ad8fabea3",
       "value": " 176/176 [00:00&lt;00:00, 323.36it/s]"
      }
     },
     "2bdfcfa9324a44e496d0f13ad8fabea3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3c7f097c41ec4c9d8a732b499882293b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4447b37abed54b5596702975876bbf85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e50735514c14a2babb1c0780b7d950f",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c99a8fe9af394e669fe0f281e99fd9e4",
       "value": 1.0
      }
     },
     "4ce949bc67074496b9c65bc7f263e022": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "5801a5c86606457a965530e4b037c73b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e50735514c14a2babb1c0780b7d950f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b55945c9e0c46999fdddd917ce2841a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4447b37abed54b5596702975876bbf85",
        "IPY_MODEL_bdf0dd6cf1c740c0a18860ad057b8db8"
       ],
       "layout": "IPY_MODEL_5801a5c86606457a965530e4b037c73b"
      }
     },
     "b7cecc3f745d41a7b03f00b1d39de83d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_006ecc8257f24549b93ec99b8aec035b",
       "max": 176.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4ce949bc67074496b9c65bc7f263e022",
       "value": 176.0
      }
     },
     "bdf0dd6cf1c740c0a18860ad057b8db8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3c7f097c41ec4c9d8a732b499882293b",
       "placeholder": "​",
       "style": "IPY_MODEL_00dcc591599749a6a5249f06f90df1c8",
       "value": " 176/? [00:00&lt;00:00, 289.83it/s]"
      }
     },
     "c99a8fe9af394e669fe0f281e99fd9e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f88b1dc5936f42968d27a89aa1d0ead6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7cecc3f745d41a7b03f00b1d39de83d",
        "IPY_MODEL_2bc237e02a6f41d0bb047f52911a4086"
       ],
       "layout": "IPY_MODEL_245d1992fe6943f484ee61f0d29ba38c"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
